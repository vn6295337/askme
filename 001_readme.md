# askme CLI

**Version**: 1.1.0  
**Status**: Production Ready âœ…  
**Repository**: https://github.com/vn6295337/askme

A privacy-first AI assistant that connects to multiple LLM providers through a secure backend proxy. Get instant answers from Google Gemini, Mistral AI, and Llama models with **zero configuration required**.

## ðŸš€ Quick Start

1. Download the latest release from GitHub
2. Extract and make executable: `chmod +x askme`
3. Start asking questions immediately: `./askme "What is machine learning?"`

**âœ… No API keys required! âœ… No configuration needed!**

## ðŸŒŸ Key Features

1. **Zero Configuration**: Works immediately without any setup
2. **Secure Backend Proxy**: API keys managed securely on server-side
3. **Multiple AI Providers**: Google Gemini, Mistral AI, Llama support
4. **Zero Data Collection**: Questions and responses never stored
5. **Privacy First**: All processing secure, no tracking or analytics
6. **Cross Platform**: Linux, macOS, Windows with WSL support
7. **Fast Response**: Under 400ms average response time
8. **Interactive Mode**: Command history and session management
9. **File Processing**: Process questions from files for batch operations

## ðŸ“¦ Installation

### System Requirements

1. **Operating System**: Linux, macOS, or Windows with WSL
2. **Java**: OpenJDK 17 or higher
3. **Memory**: 512MB RAM minimum
4. **Storage**: 50MB free space
5. **Network**: Internet connection for secure backend API

### Download Options

**Option 1: Direct Download**
```bash
wget https://github.com/vn6295337/askme/releases/latest/askme-cli.tar.gz
tar -xzf askme-cli.tar.gz
cd askme-cli
chmod +x askme
