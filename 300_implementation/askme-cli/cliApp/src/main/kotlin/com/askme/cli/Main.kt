package com.askme.cli
import kotlinx.cli.*
import kotlinx.coroutines.runBlocking
import com.askme.providers.GoogleGemini
import com.askme.providers.MistralAI
import com.askme.providers.XAI
import com.askme.providers.LlamaAI
import com.askme.providers.IntelligentProviderManager
import java.io.File

fun main(args: Array<String>) {
    val parser = ArgParser("askme")
    
    val model by parser.option(ArgType.String, shortName = "m", description = "LLM model provider").default("google")
    val promptFile by parser.option(ArgType.String, shortName = "f", description = "File containing prompt text")
    val interactive by parser.option(ArgType.Boolean, shortName = "i", description = "Interactive mode").default(false)
    val smartMode by parser.option(ArgType.Boolean, shortName = "s", description = "Smart provider selection").default(false)
    val stats by parser.option(ArgType.Boolean, description = "Show provider performance stats").default(false)
    val question by parser.argument(ArgType.String, description = "Direct question to ask").optional()
    
    parser.parse(args)
    
    suspend fun processQuery(prompt: String, provider: String): String {
        return when (provider.lowercase()) {
            "google", "gemini" -> {
                val apiKey = System.getenv("GOOGLE_API_KEY")
                if (apiKey.isNullOrBlank()) {
                    "âŒ Google API key required. Get free key at: https://makersuite.google.com/app/apikey"
                } else {
                    GoogleGemini.chat(prompt, apiKey)
                }
            }
            "mistral" -> {
                val apiKey = System.getenv("MISTRAL_API_KEY")
                if (apiKey.isNullOrBlank()) {
                    "âŒ Mistral API key required. Get key at: https://console.mistral.ai/"
                } else {
                    MistralAI.chat(prompt, apiKey)
                }
            }
            "xai", "grok" -> {
                val apiKey = System.getenv("XAI_API_KEY")
                if (apiKey.isNullOrBlank()) {
                    "âŒ XAI API key required. Get key at: https://console.x.ai/"
                } else {
                    XAI.chat(prompt, apiKey)
                }
            }
            "llama", "together" -> {
                val apiKey = System.getenv("LLAMA_API_KEY")
                if (apiKey.isNullOrBlank()) {
                    "âŒ Llama API key required. Get free key at: https://api.together.xyz/"
                } else {
                    LlamaAI.chat(prompt, apiKey)
                }
            }
            else -> "âŒ Provider $provider not implemented yet"
        }
    }
    
    runBlocking {
        when {
            stats -> {
                println(IntelligentProviderManager.getProviderStats())
            }
            smartMode && promptFile != null -> {
                val prompt = File(promptFile!!).readText()
                println("ðŸ¤– askme CLI - Smart Mode (File Input)")
                println("ðŸ“„ File: $promptFile")
                println(IntelligentProviderManager.getSmartResponse(prompt))
            }
            smartMode && interactive -> {
                println("ðŸ¤– askme CLI - Smart Interactive Mode")
                print("ðŸ“ Enter prompt: ")
                val prompt = readlnOrNull() ?: ""
                if (prompt.isNotEmpty()) {
                    println(IntelligentProviderManager.getSmartResponse(prompt))
                }
            }
            smartMode && question != null -> {
                println("ðŸ¤– askme CLI - Smart Mode")
                println(IntelligentProviderManager.getSmartResponse(question!!))
            }
            smartMode -> {
                println("ðŸ¤– askme CLI - Smart Mode")
                print("ðŸ“ Enter prompt: ")
                val prompt = readlnOrNull() ?: ""
                if (prompt.isNotEmpty()) {
                    println(IntelligentProviderManager.getSmartResponse(prompt))
                }
            }
            promptFile != null -> {
                val prompt = File(promptFile!!).readText()
                println("ðŸ¤– askme CLI - Processing prompt from file: $promptFile")
                println("ðŸŽ¯ Selected model: $model")
                println("ðŸ’¬ Response: ${processQuery(prompt, model)}")
            }
            interactive -> {
                println("ðŸ¤– askme CLI - Interactive Mode")
                println("ðŸŽ¯ Selected model: $model")
                print("ðŸ“ Enter prompt: ")
                val prompt = readlnOrNull() ?: ""
                if (prompt.isNotEmpty()) {
                    println("ðŸ’¬ Response: ${processQuery(prompt, model)}")
                }
            }
            question != null -> {
                println("ðŸ¤– askme CLI - Direct Question")
                println("ðŸŽ¯ Selected model: $model")
                println("ðŸ’¬ Response: ${processQuery(question!!, model)}")
            }
            else -> {
                println("ðŸ¤– askme CLI - LLM Client v1.1")
                println("âœ… LIVE: Google Gemini + Mistral AI + Llama")
                println("ðŸ§  NEW: Smart Provider Selection")
                println()
                println("Usage:")
                println("  askme \"your question here\"")
                println("  askme -s \"smart question\"      # Auto-select best provider")
                println("  askme -f <file> -m <provider>")
                println("  askme -i -m <provider>")
                println("  askme --stats                   # Show provider performance")
                println()
                println("Providers: google, mistral, llama")
                println("Smart Mode: Use -s for automatic provider selection")
            }
        }
    }
}
